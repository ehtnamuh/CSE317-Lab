{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/mirsazzathossain/CSE317-Lab/blob/autumn_2022/Lab_Assignment_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Wheat Seed Classification**\n",
    "\n",
    "In this assignment, you will use the [Wheat Seed Dataset](https://archive.ics.uci.edu/ml/datasets/seeds) to classify the type of wheat seed based on the measurements of the seed. The dataset contains 7 attributes and 210 instances. The attributes are:\n",
    "\n",
    "1. Area\n",
    "2. Perimeter\n",
    "3. Compactness\n",
    "4. Length of Kernel\n",
    "5. Width of Kernel\n",
    "6. Asymmetry Coefficient\n",
    "7. Length of Kernel Groove\n",
    "\n",
    "Based on the attributes, the dataset contains 3 classes:\n",
    "\n",
    "1. Kama\n",
    "2. Rosa\n",
    "3. Canadian\n",
    "\n",
    "The text file `seeds_dataset.txt` contains the dataset. The first 7 columns are the attributes and the last column is the class label. The class labels are encoded as  1, 2, and 3 for Kama, Rosa, and Canadian, respectively. The goal of this assignment is to build a classifier that can predict the type of wheat seed based on the measurements of the seed. Follow the instructions below to complete the assignment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "\n",
    "1. Download the dataset from [Github](https://minhaskamal.github.io/DownGit/#/home?url=https://github.com/mirsazzathossain/CSE317-Lab-Numerical-Methods/blob/main/datasets/seeds_dataset.txt). It should be saved as `seeds_dataset.txt`.\n",
    "2. Upload the dataset to your Google Drive and mount your Google Drive to Colab.\n",
    "3. Read the dataset using numpy's built-in function `np.genfromtxt()`. Pass the following parameters to the function:\n",
    "    - `fname`: The path to the dataset\n",
    "    - `delimiter`: The delimiter used in the dataset to separate the attributes (Hint: Use `'\\t'` as the delimiter)\n",
    "    \n",
    "4. Shuffle the dataset using `np.random.shuffle()`. Pass the following parameters to the function:\n",
    "    - `x`: The dataset\n",
    "5. Split the dataset into features and labels. The first 7 columns of the dataset are the features and the last column is the label. Use numpy's array slicing to split the dataset into features and labels. (Hint: Use `:` to select all the rows and `0:7` to select the first 7 columns for features and `7` to select the last column for labels)\n",
    "6. Split the dataset into training and testing sets. Use numpy's built-in function `np.split()` to split the dataset into training and testing sets. Pass the following parameters to the function:\n",
    "    - `ary`: The dataset\n",
    "    - `indices_or_sections`: The number of instances in the training set (Hint: Use `int(0.8 * len(dataset))` to get the number of instances in the training set)\n",
    "    - `axis`: The axis to split the dataset (Hint: Use `0` to split the dataset along the rows)\n",
    "7. Find the mean and standard deviation of each feature in the training set. Don't use numpy's built-in `mean()` and `std()` functions. Instead, use the vectorized implementation of mean and standard deviation given in the lecture. Use of loops and `np.sum()` is not allowed.\n",
    "8. In this step, you must normalize the training and test sets. Nomalization is an essential part of every machine learning project. It is used to bring all the features to the same scale. If the features are not normalized, the higher-valued features will outnumber the lower-valued ones.\n",
    "\n",
    "    For example, suppose we have a dataset with two features: the number of bedrooms in a house and the size of the garden in square feet and we are trying to forecast the rent of the residence. If the features are not normalized, the feature with higher values will take precedence over the feature with lower values. In this scenario, the garden area has a greater value. As a result, the model will make an attempt to forecast the house's price depending on the size of the garden. As a consequence, the model will be faulty since most individuals will not pay higher rent for more garden area. We need to normalize the features in order to prevent this. Let's look at the following illustration to better comprehend what we have said:\n",
    "    \n",
    "    - House 1: 4 bedrooms, 2000 sq. ft. garden\n",
    "    - House 2: 4 bedrooms, 1000 sq. ft. garden\n",
    "    - House 3: 7 bedrooms, 2500 sq. ft. garden\n",
    "\n",
    "    Considering that most people won't pay more for a larger garden, it follows that the rent for House 1 should be more comparable to House 2 than to House 3. However, if we give the aforementioned data to a k-NN classifier without normalization, it will compute the euclidean distance between the test and training examples and pick the class of the test instance based on the class of the closest training instance.\n",
    "\n",
    "    The euclidean distance between the test instance and the training instances will be:\n",
    "\n",
    "    - Distance between house 1 and house 2: $\\sqrt{(4 - 4)^2 + (2000 - 1000)^2} = 1000$\n",
    "    - Distance between house 1 and house 3: $\\sqrt{(4 - 7)^2 + (2000 - 2500)^2} = 707.1$\n",
    "\n",
    "    As you can see, the distance between houses 1 and 3 is shorter than that between houses 1 and 2. As a result, the model will forecast that house 1 will cost around the same as house 3. This is not what was anticipated. We need to normalize the features in order to prevent this. To normalize the features, subtract the mean of the feature from the feature and divide the result by the standard deviation of the feature. The formula is given below:\n",
    "\n",
    "    $$x_{normalized} = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "    where $x$ is the feature, $\\mu$ is the mean of the feature, and $\\sigma$ is the standard deviation of the feature. \n",
    "\n",
    "    Let's normalize the features in the above example. To do so, we need to find the mean and standard deviation of the features.\n",
    "\n",
    "    - Mean of the number of bedrooms: $\\frac{4 + 4 + 7}{3} = 5$\n",
    "    - Mean of the area of the garden: $\\frac{2000 + 1000 + 2500}{3} = 1833.3$\n",
    "    - Standard deviation of the number of bedrooms: $\\sqrt{\\frac{(4 - 5)^2 + (4 - 5)^2 + (7 - 5)^2}{3}} = 1.63$\n",
    "    - Standard deviation of the area of the garden: $\\sqrt{\\frac{(2000 - 1833.3)^2 + (1000 - 1833.3)^2 + (2500 - 1833.3)^2}{3}} = 707.1$ \n",
    "    \n",
    "    After normalization, the values of the features will be:\n",
    "\n",
    "    - House 1: $(4 - 5) / 1.63 = -0.62$ bedrooms, $(2000 - 1833.3) / 707.1 = 0.24$ sq. ft. garden\n",
    "    - House 2: $(4 - 5) / 1.63 = -0.62$ bedrooms, $(1000 - 1833.3) / 707.1 = -1.18$ sq. ft. garden\n",
    "    - House 3: $(7 - 5) / 1.63 = 1.24$ bedrooms, $(2500 - 1833.3) / 707.1 = 0.94$ sq. ft. garden\n",
    "\n",
    "    Now, the euclidean distance between the test instance and the training instances will be:\n",
    "\n",
    "    - Distance between house 1 and house 2: $\\sqrt{(-0.62 - (-0.62))^2 + (0.24 - (-1.18))^2} = 1.92$\n",
    "    - Distance between house 1 and house 3: $\\sqrt{(-0.62 - 1.24)^2 + (0.24 - 0.94)^2} = 2.08$\n",
    "\n",
    "    As you can see now, the distance between houses 1 and 2 is shorter than that between houses 1 and 3. The model will thus forecast that house 1 will cost about the same as house 2, according to the prediction. This is what is anticipated. This is what normalization does. It equalizes the scale of all features. This is important because it prevents the features with higher values from dominating the features with lower values.\n",
    "\n",
    "    Use the mean and standard deviation of the features in the training set that you have calculated in the previous step and normalize the training and test datasets.\n",
    "9. Now, you have to build a classifier to classify the type of wheat seed based on the measurements of the seed. Use the K-Nearest Neighbors algorithm to build the classifier. Use the Euclidean distance to find the nearest neighbors.\n",
    "\n",
    "10. Output the number of data points in the testing set and the number of correct predictions made by the classifier for each class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b148fc9bfa8b60132af830e32e1690e4e023b803e92912df15b823b90141dda6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
